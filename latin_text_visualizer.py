'''
latin_text_visualizer.py
reads lemmata in from a file and creates word embeddings, then flattens
them into 2d with PCA to graph them
bancks holmes
'''
from gensim.models import Word2Vec
from sklearn.decomposition import PCA
from matplotlib import pyplot

#read lemmata into list of strings

#make model using w2v

#flatten with PCA

#make graph

#where to limit to the 100 (or more?) most used words?